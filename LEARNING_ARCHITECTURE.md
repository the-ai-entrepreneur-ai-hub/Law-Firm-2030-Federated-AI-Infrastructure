# System Architecture: The Learning Loop

A key feature of the "Law Firm 2030" platform is its ability to improve over time. The central AI models are continuously fine-tuned based on anonymized feedback from every participating law firm. This creates a powerful network effect where the system becomes more accurate and efficient for everyone.

This learning process is designed with the same rigorous security standards as the initial document processing, ensuring that **no sensitive client data is ever used for training.**

## The Core Principle: Abstracted Human Feedback

The "training data" is not the original document. Instead, it is an **abstracted learning signal** generated by the actions of the lawyer or paralegal who reviews the AI's work. We capture the digital equivalent of these three outcomes:

1.  👍 **Accepted:** The AI's output was perfect and used as-is. This is a **strong positive signal**.
2.  👌 **Edited:** The AI's output was a good starting point but required modifications. This is a **weak positive signal**.
3.  👎 **Rejected:** The AI's output was incorrect and discarded. This is a **strong negative signal**.

The n8n workflow in each law firm is responsible for capturing this feedback and sending a secure, anonymized signal to a central learning server.

## Architectural Overview

The learning architecture involves two distinct components: the local n8n instance and your central training server.

```mermaid
graph TD
    subgraph LocalLawFirm [🔒 Local Law Firm Server (n8n)]
        direction LR
        A[📄 Raw Document] --> B(Sanitize & Anonymize);
        B --> C{🤖 LLM Generates Draft};
        C --> D[👨‍💼 Human Review];
        D -- "Accept/Edit/Reject" --> E(Generate Abstract Signal);
    end

    subgraph CentralServer [☁️ Central "Law Firm 2030" Server]
        direction TD
        F(Learning API Endpoint) --> G[📊 Feedback Database];
        G -- "Training Data" --> H(Fine-Tune New LLM Version);
    end

    E -- "✅ Secure, Anonymized Learning Signal<br/>(NO PII IS SENT)" --> F;
    H -- "Deploy v1.3" --> C;
    
    style LocalLawFirm fill:#e6ffed,stroke:#2a7e3c
    style CentralServer fill:#e6f7ff,stroke:#0077c2
```

### 1. The Local n8n Workflow (Capturing Feedback)

The local workflow is extended to include a "Human Feedback" step after the AI has generated its output.

-   **Human Review (Simulated):** A step in the workflow (e.g., a `Switch` node) simulates the user's decision to accept, edit, or reject the AI's draft.
-   **Signal Generation:** Based on the user's choice, the workflow constructs a small, anonymized JSON payload.
-   **Secure Transmission:** This payload is sent via a secure HTTPS request to the central learning API.

**Example of a Learning Signal (No PII):**
This is the only data that leaves the local law firm's server for training purposes.

```json
{
  "taskId": "unique_id_of_the_workflow_execution",
  "taskType": "document_summary",
  "modelVersion": "llama3-8b-v1.2",
  "outcome": "accepted_without_edits"
}
```

### 2. The Central Learning Server

Your central server is responsible for collecting these signals and using them to improve the AI models.

-   **Learning API Endpoint:** A secure endpoint receives the anonymized signals and stores them in a dedicated **Feedback Database**.
-   **Data Aggregation:** Over time, this database collects thousands of performance metrics from all participating law firms.
-   **Model Fine-Tuning:** The aggregated data is used to create new, improved versions of the central LLM.
    -   **Supervised Fine-Tuning (SFT):** Prompts that led to "accepted" outcomes can be used to create a high-quality dataset to further train the model on what to do.
    -   **Reinforcement Learning (DPO/RLHF):** The contrast between "accepted" and "rejected" outcomes can be used to teach the model preferences, making it more aligned and helpful.
-   **Deployment of New Models:** Once a new, improved model version is ready, it can be deployed and made available to all n8n instances, completing the learning loop.

## How to Implement Feedback in the n8n Workflow

To add this capability, the n8n workflow is modified as follows:

1.  **Add a `Switch` Node:** After the AI's output is generated and re-hydrated, a `Switch` node is used to simulate the three possible human feedback choices (Accepted, Edited, Rejected).

2.  **Add `HTTP Request` Nodes:** Each output of the `Switch` node connects to a dedicated `HTTP Request` node.

3.  **Configure Each Node:**
    -   **URL:** Points to your central learning API (e.g., `https://api.lawfirm2030.com/feedback`).
    -   **Authentication:** Uses a secure method like an API Key or Bearer Token.
    -   **Body:** Contains the structured, anonymized JSON signal, with the `outcome` field set appropriately (e.g., `"accepted_without_edits"`, `"heavily_edited"`, `"rejected"`).

This architecture ensures that the platform's core intelligence continuously evolves, providing increasing value to all users while rigorously upholding the foundational promise of data privacy and security.